import gradio as gr
import requests
import json
from typing import List, Tuple, Generator


# è·å–æœ¬åœ°æ¨¡å‹åˆ—è¡¨ï¼ˆä¿®å¤ç©ºåˆ—è¡¨å¤„ç†ï¼‰
def get_local_models() -> List[str]:
    try:
        response = requests.get("http://localhost:11434/api/tags")
        if response.status_code == 200:
            data = response.json()
            return [model['name'] for model in data.get('models', [])]
        return []
    except Exception as e:
        print(f"è·å–æ¨¡å‹å¤±è´¥: {e}")
        return ["llama3", "mistral"]  # é»˜è®¤æ¨¡å‹


# ç»Ÿä¸€å“åº”å¤„ç†æ¥å£ï¼ˆä¿®å¤æµå¼/éæµå¼å…¼å®¹é—®é¢˜ï¼‰[6,8](@ref)
def generate_response(
        message: str,
        history: List[Tuple[str, str]],
        model_name: str,
        use_stream: bool
) -> Generator[str, None, None]:
    # è½¬æ¢å¯¹è¯å†å²æ ¼å¼
    messages = []
    for human, assistant in history:
        messages.append({"role": "user", "content": human})
        messages.append({"role": "assistant", "content": assistant})
    messages.append({"role": "user", "content": message})

    url = "http://localhost:11434/api/chat"
    payload = {
        "model": model_name,
        "messages": messages,
        "stream": use_stream  # æ ¹æ®å¼€å…³å†³å®šæµå¼æ¨¡å¼
    }

    try:
        # æµå¼å“åº”å¤„ç†
        if use_stream:
            with requests.post(url, json=payload, stream=True) as response:
                response.raise_for_status()
                partial_message = ""
                for line in response.iter_lines():
                    if line:
                        chunk = json.loads(line.decode('utf-8'))
                        if "message" in chunk:
                            content = chunk["message"]["content"]
                            partial_message += content
                            yield partial_message
        # éæµå¼å“åº”å¤„ç†ï¼ˆç»Ÿä¸€è¿”å›ç”Ÿæˆå™¨ï¼‰[8](@ref)
        else:
            response = requests.post(url, json=payload)
            response.raise_for_status()
            full_response = response.json()["message"]["content"]
            yield full_response

    except Exception as e:
        yield f"è¯·æ±‚å¤±è´¥: {str(e)}"


# åˆ›å»ºGradioç•Œé¢ï¼ˆä¿®å¤äº‹ä»¶ç»‘å®šï¼‰[1](@ref)
with gr.Blocks(title="Ollama æœ¬åœ°å¯¹è¯") as app:
    gr.Markdown("## ğŸ¦™ Ollama æœ¬åœ°å¤§æ¨¡å‹å¯¹è¯ç³»ç»Ÿ")

    # æ¨¡å‹é€‰æ‹©åŒºåŸŸï¼ˆä¿®å¤ç©ºåˆ—è¡¨å¤„ç†ï¼‰
    models = get_local_models()
    with gr.Row():
        model_dropdown = gr.Dropdown(
            choices=models,
            value=models[0] if models else "",
            label="é€‰æ‹©æ¨¡å‹",
            interactive=True
        )
        refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°æ¨¡å‹åˆ—è¡¨")

    # èŠå¤©åŒºåŸŸ
    chatbot = gr.Chatbot(height=500)
    msg = gr.Textbox(label="è¾“å…¥é—®é¢˜", placeholder="åœ¨è¿™é‡Œè¾“å…¥æ‚¨çš„é—®é¢˜...")

    # æ§åˆ¶æŒ‰é’®åŒºåŸŸ
    with gr.Row():
        submit_btn = gr.Button("ğŸš€ æäº¤")
        clear_btn = gr.Button("ğŸ§¹ æ¸…é™¤å¯¹è¯")
        stream_toggle = gr.Checkbox(label="æµå¼å“åº”", value=True)


    # ä¿®å¤æ¨¡å‹åˆ·æ–°æœºåˆ¶ï¼ˆæ­£ç¡®æ›´æ–°ç°æœ‰ç»„ä»¶ï¼‰[1](@ref)
    def refresh_models():
        new_models = get_local_models()
        return gr.Dropdown.update(
            choices=new_models,
            value=new_models[0] if new_models else None
        )


    refresh_btn.click(
        refresh_models,
        inputs=[],
        outputs=[model_dropdown]
    )


    # ç»Ÿä¸€æ¶ˆæ¯å¤„ç†å‡½æ•°
    def process_message(message, history, model_name, use_stream):
        # ç”Ÿæˆå“åº”å¹¶æ›´æ–°èŠå¤©å†å²
        for response in generate_response(message, history, model_name, use_stream):
            # åˆ›å»ºæ–°å†å²è®°å½•ï¼ˆç”¨æˆ·æ¶ˆæ¯+æœ€æ–°AIå“åº”ï¼‰
            new_history = history + [(message, response)]
            # æ›´æ–°èŠå¤©æ¡†ï¼ˆå…³é”®ä¿®å¤ï¼šå®æ—¶æ›´æ–°å¯¹è¯å†å²ï¼‰[6](@ref)
            yield new_history


    # ç»‘å®šæäº¤äº‹ä»¶ï¼ˆä¿®å¤å†å²ä¼ é€’é—®é¢˜ï¼‰
    msg.submit(
        process_message,
        [msg, chatbot, model_dropdown, stream_toggle],
        [chatbot],
    ).then(lambda: "", None, [msg])  # æ¸…ç©ºè¾“å…¥æ¡†

    submit_btn.click(
        process_message,
        [msg, chatbot, model_dropdown, stream_toggle],
        [chatbot],
    ).then(lambda: "", None, [msg])

    # æ¸…é™¤å¯¹è¯
    clear_btn.click(lambda: [], None, chatbot)

# å¯åŠ¨åº”ç”¨ï¼ˆç«¯å£å†²çªæ—¶è‡ªåŠ¨åˆ‡æ¢ï¼‰[4](@ref)
app.launch(
    server_name="127.0.0.1",
    server_port=7960,
    share=False
)